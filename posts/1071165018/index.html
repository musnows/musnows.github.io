<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover"><title>【SLAM】于AutoDL云上GPU运行GCNv2_SLAM的记录 | 慕雪的寒舍</title><meta name="author" content="慕雪年华"><meta name="copyright" content="慕雪年华"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="配置GCNv2_SLAM所需环境并实现AutoDL云端运行项目的全过程记录"><meta property="og:type" content="article"><meta property="og:title" content="【SLAM】于AutoDL云上GPU运行GCNv2_SLAM的记录"><meta property="og:url" content="https://blog.musnow.top/posts/1071165018/index.html"><meta property="og:site_name" content="慕雪的寒舍"><meta property="og:description" content="配置GCNv2_SLAM所需环境并实现AutoDL云端运行项目的全过程记录"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://img.musnow.top/i/2025/02/c16bf7fe837c06718a76843ba7b923eb.png"><meta property="article:published_time" content="2025-02-02T01:57:33.000Z"><meta property="article:modified_time" content="2025-02-04T08:51:23.000Z"><meta property="article:author" content="慕雪年华"><meta property="article:tag" content="Linux"><meta property="article:tag" content="Cpp"><meta property="article:tag" content="SLAM"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://img.musnow.top/i/2025/02/c16bf7fe837c06718a76843ba7b923eb.png"><link rel="shortcut icon" href="/favicon.ico"><link rel="canonical" href="https://blog.musnow.top/posts/1071165018/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"><meta name="google-site-verification" content="iR4A6ntiwhI9JX_YDe2ZFY6DerPD7c-NaLyIDlrDguY"><meta name="msvalidate.01" content="D5CD621F38EE3FB5071F785AD4977161"><meta name="baidu-site-verification" content="codeva-aZGKJiqRSI"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.19/fancybox/fancybox.min.css" media="print" onload='this.media="all"'><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.json","preload":false,"top_n_per_article":1,"unescape":false,"languages":{"hits_empty":"找不到您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  noticeOutdate: {"limitDay":180,"position":"top","messagePrev":"距离上次更新本文已经过去了","messageNext":"天，文章部分内容可能已经过时，请注意甄别"},
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":420},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '天',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: {"limitCount":600,"languages":{"author":"作者: 慕雪年华","link":"链接: ","source":"来源: 慕雪的寒舍","info":"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    justifiedGallery: {
      js: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.js',
      css: 'https://cdnjs.cloudflare.com/ajax/libs/flickr-justified-gallery/2.1.2/fjGallery.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: true,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: true,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE={title:"【SLAM】于AutoDL云上GPU运行GCNv2_SLAM的记录",isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2025-02-04 16:51:23"}</script><noscript><style type="text/css">#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
    win.getCSS = (url,id = false) => new Promise((resolve, reject) => {
      const link = document.createElement('link')
      link.rel = 'stylesheet'
      link.href = url
      if (id) link.id = id
      link.onerror = reject
      link.onload = link.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        link.onload = link.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(link)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const detectApple = () => {
      if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><link rel="stylesheet" href="/equipment/equipment.css?1"><link rel="stylesheet" href="/rating/rating.css?1"><script>!function(r){"use strict";!function(){var t=window,s=document,e=r,c="".concat("https:"===s.location.protocol?"https://":"http://","sdk.51.la/js-sdk-pro.min.js"),i=s.createElement("script"),n=s.getElementsByTagName("script")[0];i.type="text/javascript",i.setAttribute("charset","UTF-8"),i.async=!0,i.src=c,i.id="LA_COLLECT",e.d=i;function o(){t.LA.ids.push(e)}t.LA?t.LA.ids&&o():(t.LA=r,t.LA.ids=[],o()),n.parentNode.insertBefore(i,n)}()}({id:"JwxEfuZ8fwQ1GPEq",ck:"JwxEfuZ8fwQ1GPEq"})</script><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="慕雪的寒舍" type="application/atom+xml"></head><body><div id="web_bg"></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/favicon.jpg" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">429</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">73</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">22</div></a></div><hr class="custom-hr"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 归档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/rating/"><i class="fa-fw fas fa-film"></i><span> 书·影</span></a></div><div class="menus_item"><a class="site-page" href="/qa/"><i class="fa-fw fa-fw fas fa-comment-dots"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-user-friends"></i><span> 友人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fas fa-link"></i><span> 朋友圈</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-train"></i><span> 开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><i class="fa-fw fab fa-superpowers"></i><span> 虫洞</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go.html?travel=on"><i class="fa-fw fas fa-globe-americas"></i><span> 异次元</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-glass-whiskey"></i><span> 镜像</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="https://blog.musnow.top/?utm_source=mirror"><i class="fa-fw fas fa-home"></i><span> Main</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog1.musnow.top/?utm_source=mirror"><i class="fa-fw fa-brands fa-battle-net"></i><span> Netlify</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://musnows.github.io/?utm_source=mirror"><i class="fa-fw fa-brands fa-square-github"></i><span> Github</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog2.musnow.top/?utm_source=mirror"><i class="fa-fw fa-solid fa-square-caret-up"></i><span> Vercel</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog3.musnow.top/?utm_source=mirror"><i class="fa-fw fas fa-cloud"></i><span> Cloudflare</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://keep-hexo.musnow.top/?utm_source=mirror"><i class="fa-fw fa-brands fa-kickstarter"></i><span> KeepTheme</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://musnow.blog.csdn.net/"><i class="fa-fw fas fa-copyright"></i><span> CSDN</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog.51cto.com/u_15307009"><i class="fa-fw fas fa-dice-five"></i><span> 51CTO</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fab fa-blackberry"></i><span> 更多</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 画廊</span></a></li><li><a class="site-page child" href="/equipment/"><i class="fa-fw fas fa-laptop"></i><span> 背包</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://memos.musnow.top"><i class="fa-fw fas fa-map-signs"></i><span> 说说</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://stats.uptimerobot.com/qrNpVSLkgV"><i class="fa-fw fas fa-chart-bar"></i><span> Uptime</span></a></li><li><a class="site-page child" href="/atom.xml"><i class="fa-fw fas fa-rss-square"></i><span> RSS</span></a></li></ul></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg fixed" id="page-header" style="background-image:url(https://img.musnow.top/i/2025/02/c16bf7fe837c06718a76843ba7b923eb.png)"><nav id="nav"><span id="blog-info"><a href="/" title="慕雪的寒舍"><img class="site-icon" src="/favicon.jpg"><span class="site-name">慕雪的寒舍</span></a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search" href="javascript:void(0);"><i class="fas fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-list"></i><span> 归档</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 文章</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/rating/"><i class="fa-fw fas fa-film"></i><span> 书·影</span></a></div><div class="menus_item"><a class="site-page" href="/qa/"><i class="fa-fw fa-fw fas fa-comment-dots"></i><span> 留言</span></a></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-user-friends"></i><span> 友人</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></li><li><a class="site-page child" href="/fcircle/"><i class="fa-fw fas fa-link"></i><span> 朋友圈</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.travellings.cn/go.html"><i class="fa-fw fas fa-train"></i><span> 开往</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://www.foreverblog.cn/go.html"><i class="fa-fw fab fa-superpowers"></i><span> 虫洞</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://travel.moe/go.html?travel=on"><i class="fa-fw fas fa-globe-americas"></i><span> 异次元</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fas fa-glass-whiskey"></i><span> 镜像</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="https://blog.musnow.top/?utm_source=mirror"><i class="fa-fw fas fa-home"></i><span> Main</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog1.musnow.top/?utm_source=mirror"><i class="fa-fw fa-brands fa-battle-net"></i><span> Netlify</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://musnows.github.io/?utm_source=mirror"><i class="fa-fw fa-brands fa-square-github"></i><span> Github</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog2.musnow.top/?utm_source=mirror"><i class="fa-fw fa-solid fa-square-caret-up"></i><span> Vercel</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog3.musnow.top/?utm_source=mirror"><i class="fa-fw fas fa-cloud"></i><span> Cloudflare</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://keep-hexo.musnow.top/?utm_source=mirror"><i class="fa-fw fa-brands fa-kickstarter"></i><span> KeepTheme</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://musnow.blog.csdn.net/"><i class="fa-fw fas fa-copyright"></i><span> CSDN</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://blog.51cto.com/u_15307009"><i class="fa-fw fas fa-dice-five"></i><span> 51CTO</span></a></li></ul></div><div class="menus_item"><a class="site-page group" href="javascript:void(0);"><i class="fa-fw fab fa-blackberry"></i><span> 更多</span><i class="fas fa-chevron-down"></i></a><ul class="menus_item_child"><li><a class="site-page child" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></li><li><a class="site-page child" href="/gallery/"><i class="fa-fw fas fa-images"></i><span> 画廊</span></a></li><li><a class="site-page child" href="/equipment/"><i class="fa-fw fas fa-laptop"></i><span> 背包</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://memos.musnow.top"><i class="fa-fw fas fa-map-signs"></i><span> 说说</span></a></li><li><a class="site-page child" target="_blank" rel="noopener" href="https://stats.uptimerobot.com/qrNpVSLkgV"><i class="fa-fw fas fa-chart-bar"></i><span> Uptime</span></a></li><li><a class="site-page child" href="/atom.xml"><i class="fa-fw fas fa-rss-square"></i><span> RSS</span></a></li></ul></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">【SLAM】于AutoDL云上GPU运行GCNv2_SLAM的记录</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-02-02T01:57:33.000Z" title="发表于 2025-02-02 09:57:33">2025-02-02</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2025-02-04T08:51:23.000Z" title="更新于 2025-02-04 16:51:23">2025-02-04</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/">编程学习</a><i class="fas fa-angle-right post-meta-separator"></i><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%BC%96%E7%A8%8B%E5%AD%A6%E4%B9%A0/Linux/">Linux</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">8.3k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>38分钟</span></span><span class="post-meta-separator">|</span><span data-flag-title="【SLAM】于AutoDL云上GPU运行GCNv2_SLAM的记录"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="ArtalkPV"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>配置GCNv2_SLAM所需环境并实现AutoDL云端运行项目的全过程记录。</p><h2 id="1-引子"><a href="#1-引子" class="headerlink" title="1. 引子"></a>1. 引子</h2><p>前几天写了一篇在本地虚拟机里面CPU运行GCNv2_SLAM项目的博客：<a href="https://blog.musnow.top/posts/1589125738/">链接</a>，关于GCNv2_SLAM项目相关的介绍请移步此文章，本文不再重复说明。</p><ul><li><a target="_blank" rel="noopener" href="https://ieeexplore.ieee.org/document/8758836">GCNv2: Efficient Correspondence Prediction for Real-Time SLAM</a>;</li><li><a target="_blank" rel="noopener" href="https://github.com/jiexiong2016/GCNv2_SLAM">github.com&#x2F;jiexiong2016&#x2F;GCNv2_SLAM</a>;</li></ul><p>在之前的测试中，本地虚拟机CPU运行的效果非常差，推理速度只有可怜兮兮的<code>0.5 HZ</code>，但是我手头又没有带显卡的环境，所以想到了可以去网上租个带显卡的容器化环境。</p><p>AutoDL就是一个租GPU环境的平台: <a target="_blank" rel="noopener" href="https://www.autodl.com/">https://www.autodl.com/</a>，而且autodl租显卡是可以按小时付费的，比按月付费的更加划算，更好过自己买个显卡在本地倒腾ubuntu环境，所以就直接开整了！</p><p>先注册一个AutoDL的账户，给里面充值一丢丢钱，然后就可以租一个显卡容器化环境来运行GCNv2_SLAM啦！</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/c16bf7fe837c06718a76843ba7b923eb.png" alt="image.png"></p><h2 id="2-AutoDL环境选择"><a href="#2-AutoDL环境选择" class="headerlink" title="2. AutoDL环境选择"></a>2. AutoDL环境选择</h2><p>老版本PyTorch的镜像由于4090无法使用太低的cuda版本导致无法选择，如果需要使用更低版本的pytorch镜像，则需要租用2080ti或者1080ti显卡的环境。</p><p>2080ti显卡可以选择如下环境，实测可用：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PyTorch  1.5.1</span><br><span class="line">Python  3.8(ubuntu18.04)</span><br><span class="line">Cuda  10.1</span><br></pre></td></tr></table></figure><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/9f33c7eb80a44080fd587573e315f769.png" alt="image.png"></p><p>创建环境后，建议使用左侧的ssh登录指令直接在本地终端里面执行，登录到云端。如果你没有本地的ssh终端，也可以点击JupyterLab里面的终端来运行命令。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/2a97018925b0281e8faeb64ef8cb5ff9.png" alt="image.png"></p><p>后文涉及到下载很多文件，如果从github下载很慢，可以在本地下好之后通过JupyterLab传到云端去。注意传文件之前要先在文件列表里面选好目标的目录。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/a924fd5dea1fa0ef7a020aa1487a8a37.png" alt="image.png"></p><p>还可以尝试autodl自带的代理：<a target="_blank" rel="noopener" href="https://www.autodl.com/docs/network_turbo/">www.autodl.com/docs/network_turbo&#x2F;</a>，但是慕雪试用的时候这个代理一直返回503，不可用状态。</p><h2 id="3-依赖安装"><a href="#3-依赖安装" class="headerlink" title="3. 依赖安装"></a>3. 依赖安装</h2><h3 id="3-1-需要的apt包安装"><a href="#3-1-需要的apt包安装" class="headerlink" title="3.1. 需要的apt包安装"></a>3.1. 需要的apt包安装</h3><p>运行之前先更新一下环境，这部分操作和在本地虚拟机里面安装环境都是一样的。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get update -y</span><br><span class="line">sudo apt-get upgrade -y</span><br></pre></td></tr></table></figure><p>更新的时候会有一个新的sshd配置的提醒，这里直接选择1用新版本配置就可以了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">A new version (/tmp/file1bBLK4) of configuration file /etc/ssh/sshd_config is available, but the version installed currently has been</span><br><span class="line">locally modified.</span><br><span class="line"></span><br><span class="line">  1. install the package maintainer&#x27;s version             5. show a 3-way difference between available versions</span><br><span class="line">  2. keep the local version currently installed           6. do a 3-way merge between available versions</span><br><span class="line">  3. show the differences between the versions            7. start a new shell to examine the situation</span><br><span class="line">  4. show a side-by-side difference between the versions</span><br><span class="line">What do you want to do about modified configuration file sshd_config? 1</span><br></pre></td></tr></table></figure><p>因为选了Pytorch镜像，Python工具组系统已经自带了，不需要安装。</p><p>安装要用的到的工具包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 工具包</span></span><br><span class="line">sudo apt-get install -y \</span><br><span class="line">    apt-utils \</span><br><span class="line">    curl wget unzip zip \</span><br><span class="line">    cmake make automake \</span><br><span class="line">    openssh-server \</span><br><span class="line">    net-tools \</span><br><span class="line">    vim git gcc g++</span><br></pre></td></tr></table></figure><p>安装x11相关的依赖包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># x11 for gui</span></span><br><span class="line">sudo apt-get install -y  \</span><br><span class="line">    libx11-xcb1 \</span><br><span class="line">    libfreetype6 \</span><br><span class="line">    libdbus-1-3 \</span><br><span class="line">    libfontconfig1 \</span><br><span class="line">    libxkbcommon0   \</span><br><span class="line">    libxkbcommon-x11-0</span><br></pre></td></tr></table></figure><h3 id="3-2-Pangolin-6-0"><a href="#3-2-Pangolin-6-0" class="headerlink" title="3.2. Pangolin-6.0"></a>3.2. Pangolin-6.0</h3><h4 id="3-2-1-依赖项安装"><a href="#3-2-1-依赖项安装" class="headerlink" title="3.2.1. 依赖项安装"></a>3.2.1. 依赖项安装</h4><p>安装Pangolin之前先安装如下依赖包</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># pangolin</span></span><br><span class="line">sudo apt-get install -y \</span><br><span class="line">    libgl1-mesa-dev \</span><br><span class="line">    libglew-dev \</span><br><span class="line">    libboost-dev \</span><br><span class="line">    libboost-thread-dev \</span><br><span class="line">    libboost-filesystem-dev \</span><br><span class="line">    libpython2.7-dev \</span><br><span class="line">    libglu1-mesa-dev freeglut3-dev</span><br></pre></td></tr></table></figure><p>在AutoDL的PyTorch 1.5.1镜像中，安装Pangolin依赖包的时候的终端输出如下，出现了<strong>依赖项版本冲突</strong>问题。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~# apt-get install -y     libgl1-mesa-dev     libglew-dev     libboost-dev     libboost-thread-dev     libboost-filesystem-dev     libpython2.7-dev     libglu1-mesa-dev freeglut3-dev</span><br><span class="line">Reading package lists... Done</span><br><span class="line">Building dependency tree     </span><br><span class="line">Reading state information... Done</span><br><span class="line">Some packages could not be installed. This may mean that you have</span><br><span class="line">requested an impossible situation or if you are using the unstable</span><br><span class="line">distribution that some required packages have not yet been created</span><br><span class="line">or been moved out of Incoming.</span><br><span class="line">The following information may help to resolve the situation:</span><br><span class="line"></span><br><span class="line">The following packages have unmet dependencies:</span><br><span class="line"> freeglut3-dev : Depends: libxext-dev but it is not going to be installed</span><br><span class="line">                 Depends: libxt-dev but it is not going to be installed</span><br><span class="line"> libgl1-mesa-dev : Depends: mesa-common-dev (= 20.0.8-0ubuntu1~18.04.1) but it is not going to be installed</span><br><span class="line">                   Depends: libx11-dev but it is not going to be installed</span><br><span class="line">                   Depends: libx11-xcb-dev but it is not going to be installed</span><br><span class="line">                   Depends: libxdamage-dev but it is not going to be installed</span><br><span class="line">                   Depends: libxext-dev but it is not going to be installed</span><br><span class="line">                   Depends: libxfixes-dev but it is not going to be installed</span><br><span class="line">                   Depends: libxxf86vm-dev but it is not going to be installed</span><br><span class="line">E: Unable to correct problems, you have held broken packages.</span><br></pre></td></tr></table></figure><p>这里依赖冲突的问题是安装的x11依赖包有两个版本过高了，需要降级下面这两个依赖包。<strong>如果你安装依赖项时没有出现依赖项冲突就成功安装了，则不需要执行下面的降级命令</strong>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y \</span><br><span class="line">    libx11-xcb1=2:1.6.4-3ubuntu0.4 \</span><br><span class="line">    libx11-6=2:1.6.4-3ubuntu0.4</span><br></pre></td></tr></table></figure><p>降级成功后，重新执行上述安装Pangolin依赖项的命令，就能成功安装了。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/612a64181be8520b7fc2020b05279a54.png" alt="image.png"></p><h4 id="3-2-2-编译安装"><a href="#3-2-2-编译安装" class="headerlink" title="3.2.2. 编译安装"></a>3.2.2. 编译安装</h4><p>随后使用如下命令来编译安装Pangolin，Github地址：<a target="_blank" rel="noopener" href="https://github.com/stevenlovegrove/Pangolin/releases/tag/v0.6">Pangolin-0.6</a>。</p><p>建议这些依赖包都进入<code>~/autodl-tmp</code>数据盘来下载和安装，这样即便后续需要更换镜像也能保留数据，不需要重新下载</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget -O Pangolin-0.6.tar.gz https://github.com/stevenlovegrove/Pangolin/archive/refs/tags/v0.6.tar.gz</span><br><span class="line"><span class="comment"># 解压</span></span><br><span class="line">tar -zxvf Pangolin-0.6.tar.gz</span><br><span class="line"></span><br><span class="line"><span class="built_in">pushd</span> Pangolin-0.6</span><br><span class="line">    <span class="built_in">rm</span> -rf build</span><br><span class="line">    <span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">    <span class="comment"># 编译安装 </span></span><br><span class="line">    cmake -DCPP11_NO_BOOST=1 ..</span><br><span class="line">    make -j$(<span class="built_in">nproc</span>)</span><br><span class="line">    make install</span><br><span class="line">    <span class="comment"># 刷新动态库</span></span><br><span class="line">    ldconfig</span><br><span class="line"><span class="built_in">popd</span></span><br></pre></td></tr></table></figure><p>编译安装成功</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/1c07fc6dbf06de466e2a7e2a231cb489.png" alt="image.png"></p><p>示例代码HelloPangolin也能编译成功，只不过当前我们还没有配置GUI，所以会有x11错误无法运行（后文会讲述如何配置GUI和VNC）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/pkg/Pangolin-0.6/build# cd ../examples/HelloPangolin</span><br><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/pkg/Pangolin-0.6/examples/HelloPangolin# mkdir build &amp;&amp; cd build</span><br><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/pkg/Pangolin-0.6/examples/HelloPangolin/build# cmake ..</span><br><span class="line">-- The C compiler identification is GNU 7.5.0</span><br><span class="line">-- The CXX compiler identification is GNU 7.5.0</span><br><span class="line">-- Check for working C compiler: /usr/bin/cc</span><br><span class="line">-- Check for working C compiler: /usr/bin/cc -- works</span><br><span class="line">-- Detecting C compiler ABI info</span><br><span class="line">-- Detecting C compiler ABI info - done</span><br><span class="line">-- Detecting C compile features</span><br><span class="line">-- Detecting C compile features - done</span><br><span class="line">-- Check for working CXX compiler: /usr/bin/c++</span><br><span class="line">-- Check for working CXX compiler: /usr/bin/c++ -- works</span><br><span class="line">-- Detecting CXX compiler ABI info</span><br><span class="line">-- Detecting CXX compiler ABI info - done</span><br><span class="line">-- Detecting CXX compile features</span><br><span class="line">-- Detecting CXX compile features - done</span><br><span class="line">CMake Warning (dev) in CMakeLists.txt:</span><br><span class="line">  No cmake_minimum_required command is present.  A line of code such as</span><br><span class="line"></span><br><span class="line">    cmake_minimum_required(VERSION 3.10)</span><br><span class="line"></span><br><span class="line">  should be added at the top of the file.  The version specified may be lower</span><br><span class="line">  if you wish to support older CMake versions for this project.  For more</span><br><span class="line">  information run &quot;cmake --help-policy CMP0000&quot;.</span><br><span class="line">This warning is for project developers.  Use -Wno-dev to suppress it.</span><br><span class="line"></span><br><span class="line">-- Configuring done</span><br><span class="line">CMake Warning (dev) at CMakeLists.txt:5 (add_executable):</span><br><span class="line">  Policy CMP0003 should be set before this line.  Add code such as</span><br><span class="line"></span><br><span class="line">    if(COMMAND cmake_policy)</span><br><span class="line">      cmake_policy(SET CMP0003 NEW)</span><br><span class="line">    endif(COMMAND cmake_policy)</span><br><span class="line"></span><br><span class="line">  as early as possible but after the most recent call to</span><br><span class="line">  cmake_minimum_required or cmake_policy(VERSION).  This warning appears</span><br><span class="line">  because target &quot;HelloPangolin&quot; links to some libraries for which the linker</span><br><span class="line">  must search:</span><br><span class="line"></span><br><span class="line">    rt, pthread, rt, pthread</span><br><span class="line"></span><br><span class="line">  and other libraries with known full path:</span><br><span class="line"></span><br><span class="line">    /usr/local/lib/libpangolin.so</span><br><span class="line"></span><br><span class="line">  CMake is adding directories in the second list to the linker search path in</span><br><span class="line">  case they are needed to find libraries from the first list (for backwards</span><br><span class="line">  compatibility with CMake 2.4).  Set policy CMP0003 to OLD or NEW to enable</span><br><span class="line">  or disable this behavior explicitly.  Run &quot;cmake --help-policy CMP0003&quot; for</span><br><span class="line">  more information.</span><br><span class="line">This warning is for project developers.  Use -Wno-dev to suppress it.</span><br><span class="line"></span><br><span class="line">-- Generating done</span><br><span class="line">-- Build files have been written to: /root/pkg/Pangolin-0.6/examples/HelloPangolin/build</span><br><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/pkg/Pangolin-0.6/examples/HelloPangolin/build# make</span><br><span class="line">Scanning dependencies of target HelloPangolin</span><br><span class="line">[ 50%] Building CXX object CMakeFiles/HelloPangolin.dir/main.o</span><br><span class="line">[100%] Linking CXX executable HelloPangolin</span><br><span class="line">[100%] Built target HelloPangolin</span><br><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/pkg/Pangolin-0.6/examples/HelloPangolin/build# ./HelloPangolin </span><br><span class="line">terminate called after throwing an instance of &#x27;std::runtime_error&#x27;</span><br><span class="line">  what():  Pangolin X11: Failed to open X display</span><br><span class="line">Aborted (core dumped)</span><br></pre></td></tr></table></figure><h3 id="3-3-OpenCV-3-4-5"><a href="#3-3-OpenCV-3-4-5" class="headerlink" title="3.3. OpenCV 3.4.5"></a>3.3. OpenCV 3.4.5</h3><p>先安装依赖项</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install -y \</span><br><span class="line">	build-essential libgtk2.0-dev \</span><br><span class="line">	libavcodec-dev libavformat-dev \</span><br><span class="line">	libjpeg.dev libtiff5.dev libswscale-dev \</span><br><span class="line">	libcanberra-gtk-module</span><br></pre></td></tr></table></figure><p>因为AutoDL环境是amd64，所以直接用下面的命令安装libjasper就OK了，不需要额外的处理</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># amd64 添加新源后继续安装</span></span><br><span class="line">sudo apt-get install -y software-properties-common </span><br><span class="line">sudo add-apt-repository <span class="string">&quot;deb http://security.ubuntu.com/ubuntu xenial-security main&quot;</span></span><br><span class="line">sudo apt-get -y update </span><br><span class="line">sudo apt-get install -y libjasper1 libjasper-dev</span><br></pre></td></tr></table></figure><p>以下是安装libjasper的截图</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/5902d476da93c3adfb6af65231e3d168.png" alt="image.png"></p><p>安装好了依赖项后，使用如下命令编译opencv，Github地址：<a target="_blank" rel="noopener" href="https://github.com/opencv/opencv/releases/tag/3.4.5">opencv的3.4.5版本</a>。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载和解压</span></span><br><span class="line">wget -O opencv-3.4.5.tar.gz https://github.com/opencv/opencv/archive/refs/tags/3.4.5.tar.gz</span><br><span class="line">tar -zxvf opencv-3.4.5.tar.gz</span><br><span class="line"><span class="comment"># 开始编译和安装</span></span><br><span class="line"><span class="built_in">pushd</span> opencv-3.4.5</span><br><span class="line">    <span class="built_in">rm</span> -rf build</span><br><span class="line">    <span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build </span><br><span class="line">    <span class="comment"># 构建和编译安装，-j4代表4线程并发</span></span><br><span class="line">    cmake -D CMAKE_BUILD_TYPE=Release -D CMAKE_INSTALL_PREFIX=/usr/local ..</span><br><span class="line">    make -j$(<span class="built_in">nproc</span>)</span><br><span class="line">    make install</span><br><span class="line">    <span class="comment"># 刷新动态库</span></span><br><span class="line">    ldconfig</span><br><span class="line"><span class="built_in">popd</span></span><br></pre></td></tr></table></figure><p>正常编译安装，莫得问题</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/2fc7a4798d20675737e1db1f7539b952.png" alt="image.png"></p><h3 id="3-4-Eigen-3-7"><a href="#3-4-Eigen-3-7" class="headerlink" title="3.4. Eigen 3.7"></a>3.4. Eigen 3.7</h3><p>Eigen包在gitlab里面下载：<a target="_blank" rel="noopener" href="https://gitlab.com/libeigen/eigen/-/releases/3.3.7">gitlab.com&#x2F;libeigen&#x2F;eigen&#x2F;-&#x2F;releases&#x2F;3.3.7</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 下载</span></span><br><span class="line">wget -O eigen-3.3.7.tar.gz https://gitlab.com/libeigen/eigen/-/archive/3.3.7/eigen-3.3.7.tar.gz</span><br><span class="line">tar -zxvf eigen-3.3.7.tar.gz</span><br><span class="line"><span class="comment"># 开始编译和安装</span></span><br><span class="line"><span class="built_in">cd</span> eigen-3.3.7</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make &amp;&amp; make install</span><br><span class="line"><span class="comment"># 拷贝路径（避免头文件引用不到）</span></span><br><span class="line">sudo <span class="built_in">cp</span> -r /usr/local/include/eigen3/Eigen /usr/local/include</span><br></pre></td></tr></table></figure><p>还是用相同的cpp的demo代码来测试是否安装成功（直接g++编译就可以了）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="comment">//需要将头文件从 /usr/local/include/eigen3/ 复制到 /usr/local/include</span></span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;Eigen/Dense&gt;</span></span></span><br><span class="line"><span class="comment">//using Eigen::MatrixXd;</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> Eigen;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> Eigen::internal;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> Eigen::Architecture;</span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"><span class="function"><span class="type">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;*******************1D-object****************&quot;</span>&lt;&lt;endl;</span><br><span class="line">        Vector4d v1;</span><br><span class="line">        v1&lt;&lt; <span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;v1=\n&quot;</span>&lt;&lt;v1&lt;&lt;endl;</span><br><span class="line"> </span><br><span class="line">        <span class="function">VectorXd <span class="title">v2</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line">        v2&lt;&lt;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;v2=\n&quot;</span>&lt;&lt;v2&lt;&lt;endl;</span><br><span class="line"> </span><br><span class="line">        Array4i v3;</span><br><span class="line">        v3&lt;&lt;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>,<span class="number">4</span>;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;v3=\n&quot;</span>&lt;&lt;v3&lt;&lt;endl;</span><br><span class="line"> </span><br><span class="line">        <span class="function">ArrayXf <span class="title">v4</span><span class="params">(<span class="number">3</span>)</span></span>;</span><br><span class="line">        v4&lt;&lt;<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>;</span><br><span class="line">        cout&lt;&lt;<span class="string">&quot;v4=\n&quot;</span>&lt;&lt;v4&lt;&lt;endl;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>正常编译运行</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/pkg/eigen-3.3.7/build# g++ test.cpp -o t</span><br><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/pkg/eigen-3.3.7/build# ./t</span><br><span class="line">*******************1D-object****************</span><br><span class="line">v1=</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">v2=</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">v3=</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">v4=</span><br><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td></tr></table></figure><h3 id="3-5-Libtorch-1-5-0"><a href="#3-5-Libtorch-1-5-0" class="headerlink" title="3.5. Libtorch 1.5.0"></a>3.5. Libtorch 1.5.0</h3><h4 id="3-5-1-关于手工编译的说明"><a href="#3-5-1-关于手工编译的说明" class="headerlink" title="3.5.1. 关于手工编译的说明"></a>3.5.1. 关于手工编译的说明</h4><p>因为我们选择的autodl环境里面已经带了Pytorch了，所以可以不需要自己手动从源码构建了。</p><p>我尝试过从源码构建pytorch 1.1.0版本，会在构建的半路被killed掉，不清楚问题在哪里，猜测是构建占用内存cpu过多导致的，当时被kill掉的输出如下，大约在74%的时候，前后都没有出现error，就直接被干掉了。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/b14ebcee0574f7686f2718cb7e1b1f33.png" alt="image.png"><br><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/544077ff057e3ee249dddf844975dd5f.png" alt="image.png"></p><h4 id="3-5-2-不能使用本地已有的版本"><a href="#3-5-2-不能使用本地已有的版本" class="headerlink" title="3.5.2. 不能使用本地已有的版本"></a>3.5.2. 不能使用本地已有的版本</h4><p>我们选用的autodl镜像里面其实已经自带了一个可用的Torch目录，路径如下所示</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/root/miniconda3/lib/python3.8/site-packages/torch/share/cmake/Torch</span><br></pre></td></tr></table></figure><p>但是这个目录中引用的libtorch预编译版本是不包含C++11ABI兼容机制的，会最终导致Pangolin链接失败，<strong>错误输出如下所示</strong>。这个链接失败的问题和使用的Pangolin版本没有关系，尝试过Pangolin5.0和6.0都会链接失败。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[100%] Linking CXX executable ../GCN2/rgbd_gcn</span><br><span class="line">../lib/libORB_SLAM2.so: undefined reference to `pangolin::Split(std::string const&amp;, char)&#x27;</span><br><span class="line">../lib/libORB_SLAM2.so: undefined reference to `pangolin::CreatePanel(std::string const&amp;)&#x27;</span><br><span class="line">../lib/libORB_SLAM2.so: undefined reference to `DBoW2::FORB::fromString(cv::Mat&amp;, std::string const&amp;)&#x27;</span><br><span class="line">../lib/libORB_SLAM2.so: undefined reference to `pangolin::BindToContext(std::string)&#x27;</span><br><span class="line">../lib/libORB_SLAM2.so: undefined reference to `DBoW2::FORB::toString(cv::Mat const&amp;)&#x27;</span><br><span class="line">../lib/libORB_SLAM2.so: undefined reference to `pangolin::CreateWindowAndBind(std::string, int, int, pangolin::Params const&amp;)&#x27;</span><br><span class="line">collect2: error: ld returned 1 exit status</span><br><span class="line">CMakeFiles/rgbd_gcn.dir/build.make:152: recipe for target &#x27;../GCN2/rgbd_gcn&#x27; failed</span><br><span class="line">make[2]: *** [../GCN2/rgbd_gcn] Error 1</span><br><span class="line">CMakeFiles/Makefile2:67: recipe for target &#x27;CMakeFiles/rgbd_gcn.dir/all&#x27; failed</span><br><span class="line">make[1]: *** [CMakeFiles/rgbd_gcn.dir/all] Error 2</span><br><span class="line">Makefile:83: recipe for target &#x27;all&#x27; failed</span><br><span class="line">make: *** [all] Error 2</span><br></pre></td></tr></table></figure><p>在GCNv2的GITHUB中是有提到这个问题的，翻译过来就是不要使用预编译版本的libtorch，因为会出现CXX11 ABI导致的连接错误。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/28648c35c47c9423677cbc031ee7b21b.png" alt="image.png"></p><p>在Pytroch 1.3.0之后的版本，官方就已经提供了带CXX11 ABI兼容的预编译版本了，所以可以下载预编译包之后来使用。直接使用容器内的libtorch依旧会有链接问题。</p><h4 id="3-5-3-下载预编译版本"><a href="#3-5-3-下载预编译版本" class="headerlink" title="3.5.3. 下载预编译版本"></a>3.5.3. 下载预编译版本</h4><p>最开始我选择的就是pytorch1.1.0版本的镜像，但是由于没办法从源码编译所以切换成了pytorch1.5.1的镜像。因为在pytorch1.3.0之后官方才提供了CXX11 ABI兼容的预编译包，在这之前的版本都需要手工编译，否则会有链接错误。</p><p>我们需要做的操作是从官网上下一个带CXX11 ABI兼容的libtorch预编译包，下载地址中包含<code>cxx11-abi</code>的才是带有CXX11 ABI兼容的。1.5.0版本的libtorch包下载地址如下，其中cu101代表cuda10.1，最后的libtorch版本是1.5.0（libtorch 1.5.1版本的包下不了）</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://download.pytorch.org/libtorch/cu101/libtorch-cxx11-abi-shared-with-deps-1.5.0.zip</span><br></pre></td></tr></table></figure><p>直接通过unzip解压这个目录，就能得到一个libtorch文件夹，后文需要的<code>TORCH_PATH</code>在libtorch的<code>libtorch/share/cmake/Torch</code>目录中就有：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/autodl-tmp# ls libtorch/share/cmake/Torch</span><br><span class="line">TorchConfig.cmake  TorchConfigVersion.cmake</span><br></pre></td></tr></table></figure><p>预编译的libtorch包容量都挺大的，建议本地提前下好然后上传到autodl里面，在autodl里面直接下载太耗时了，都是钱呐！</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/026d3b62639df227067ffd0ca0c204ef.png" alt="image.png"></p><h2 id="4-编译GCNv2-SLAM"><a href="#4-编译GCNv2-SLAM" class="headerlink" title="4. 编译GCNv2_SLAM"></a>4. 编译GCNv2_SLAM</h2><p>上正主了，克隆一下代码</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/jiexiong2016/GCNv2_SLAM.git</span><br></pre></td></tr></table></figure><p>因为这次是在autodl环境中跑，有了显卡，pytorch的版本和之前的博客中的完全不一样，所以需要修改的代码内容也不一样。可以参考博客 <a target="_blank" rel="noopener" href="https://blog.csdn.net/yangyu0515/article/details/136621489">GCNv2_SLAM-CPU详细安装教程(ubuntu18.04)-CSDN博客</a> 中的说明进行修改。</p><h3 id="4-1-修改build-sh"><a href="#4-1-修改build-sh" class="headerlink" title="4.1. 修改build.sh"></a>4.1. 修改build.sh</h3><p>预编译版本的<code>TORCH_PATH</code>在压缩包解压后libtorch目录中，即<code>libtorch/share/cmake/Torch</code>目录。修改build.sh脚本中的路径为此目录就可以了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">-DTORCH_PATH=/root/autodl-tmp/libtorch/share/cmake/Torch</span><br></pre></td></tr></table></figure><p>修改之后就可以开始编译，并根据报错来解决后面的一些问题了</p><h3 id="4-2-修改代码兼容高版本libtorch"><a href="#4-2-修改代码兼容高版本libtorch" class="headerlink" title="4.2. 修改代码兼容高版本libtorch"></a>4.2. 修改代码兼容高版本libtorch</h3><p>这部分修改可以在我的Github仓库中找到：<a target="_blank" rel="noopener" href="https://github.com/musnows/GCNv2_SLAM/tree/pytorch1.5.0">github.com&#x2F;musnows&#x2F;GCNv2_SLAM&#x2F;tree&#x2F;pytorch1.5.0</a></p><h4 id="4-2-1-C-14编译配置"><a href="#4-2-1-C-14编译配置" class="headerlink" title="4.2.1. C++14编译配置"></a>4.2.1. C++14编译配置</h4><p>初次运行会出现如下错误，高版本的torch需要C++14来编译，因为用到了14的新特性</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">/root/autodl-tmp/libtorch/include/c10/util/C++17.h:27:2: error: #error You need C++14 to compile PyTorch</span><br><span class="line">   27 | #error You need C++14 to compile PyTorch</span><br><span class="line">      |  ^~~~~</span><br></pre></td></tr></table></figure><p>需要我们修改camke文件，修改<code>GCNv2_SLAM/CMakeLists.txt</code>，新增如下内容</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 头部插入</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD <span class="number">14</span>)</span><br><span class="line"><span class="keyword">set</span>(CMAKE_CXX_STANDARD_REQUIRED <span class="keyword">ON</span>)</span><br><span class="line"><span class="comment"># 修改尾部的11为14</span></span><br><span class="line"><span class="comment"># set_property(TARGET rgbd_gcn PROPERTY CXX_STANDARD 11)</span></span><br><span class="line"><span class="keyword">set_property</span>(<span class="keyword">TARGET</span> rgbd_gcn PROPERTY CXX_STANDARD <span class="number">14</span>)</span><br></pre></td></tr></table></figure><p>然后还需要注释掉和C++11判断相关的cmake配置，也就是下面这一堆</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#Check C++11 or C++0x support</span></span><br><span class="line"><span class="comment">#include(CheckCXXCompilerFlag)</span></span><br><span class="line"><span class="comment">#CHECK_CXX_COMPILER_FLAG(&quot;-std=c++11&quot; COMPILER_SUPPORTS_CXX11)</span></span><br><span class="line"><span class="comment">#CHECK_CXX_COMPILER_FLAG(&quot;-std=c++0x&quot; COMPILER_SUPPORTS_CXX0X)</span></span><br><span class="line"><span class="comment">#if(COMPILER_SUPPORTS_CXX11)</span></span><br><span class="line"><span class="comment">#   set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++11&quot;)</span></span><br><span class="line">   <span class="keyword">add_definitions</span>(-DCOMPILEDWITHC11)</span><br><span class="line"><span class="comment">#   message(STATUS &quot;Using flag -std=c++11.&quot;)</span></span><br><span class="line"><span class="comment">#elseif(COMPILER_SUPPORTS_CXX0X)</span></span><br><span class="line"><span class="comment">#   set(CMAKE_CXX_FLAGS &quot;$&#123;CMAKE_CXX_FLAGS&#125; -std=c++0x&quot;)</span></span><br><span class="line"><span class="comment">#   add_definitions(-DCOMPILEDWITHC0X)</span></span><br><span class="line"><span class="comment">#   message(STATUS &quot;Using flag -std=c++0x.&quot;)</span></span><br><span class="line"><span class="comment">#else()</span></span><br><span class="line"><span class="comment">#   message(FATAL_ERROR &quot;The compiler $&#123;CMAKE_CXX_COMPILER&#125; has no C++11 support. Please use a different C++ compiler.&quot;)</span></span><br><span class="line"><span class="comment">#endif()</span></span><br></pre></td></tr></table></figure><p>其中<code>add_definitions(-DCOMPILEDWITHC11)</code>不要注释掉，有用！</p><p>修改cmake后需要删除<code>GCNv2_SLAM/build</code>目录重新运行build.sh脚本，否则修改可能不会生效。</p><h4 id="4-2-2-缺少对应的operator-x3D"><a href="#4-2-2-缺少对应的operator-x3D" class="headerlink" title="4.2.2. 缺少对应的operator&#x3D;"></a>4.2.2. 缺少对应的operator&#x3D;</h4><p>报错如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">/root/autodl-tmp/GCNv2_SLAM/src/GCNextractor.cc: In constructor ‘ORB_SLAM2::GCNextractor::GCNextractor(int, float, int, int, int)’:</span><br><span class="line">/root/autodl-tmp/GCNv2_SLAM/src/GCNextractor.cc:218:37: error: no match for ‘operator=’ (operand types are ‘std::shared_ptr&lt;torch::jit::Module&gt;’ and ‘torch::jit::Module’)</span><br><span class="line">     module = torch::jit::load(net_fn);</span><br><span class="line">                                     ^</span><br><span class="line">In file included from /usr/include/c++/7/memory:81:0,</span><br><span class="line">                 from /root/miniconda3/lib/python3.8/site-packages/torch/include/c10/core/Allocator.h:4,</span><br><span class="line">                 from /root/miniconda3/lib/python3.8/site-packages/torch/include/ATen/ATen.h:3,</span><br><span class="line">                 from /root/miniconda3/lib/python3.8/site-packages/torch/include/torch/csrc/api/include/torch/types.h:3,</span><br><span class="line">                 from /root/miniconda3/lib/python3.8/site-packages/torch/include/torch/script.h:3,</span><br><span class="line">                 from /root/autodl-tmp/GCNv2_SLAM/include/GCNextractor.h:24,</span><br><span class="line">                 from /root/autodl-tmp/GCNv2_SLAM/src/GCNextractor.cc:63:</span><br></pre></td></tr></table></figure><p>问题主要是<code>torch::jit::Module</code>入参不再是一个指针了，所以要把<code>shared_ptr</code>给改成普通对象。</p><p>修改<code>GCNv2_SLAM/include/GCNextractor.h</code>文件的99行：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//原代码</span></span><br><span class="line">std::shared_ptr&lt;torch::jit::script::Module&gt; <span class="keyword">module</span>;</span><br><span class="line"><span class="comment">//更改为</span></span><br><span class="line">torch::jit::script::Module <span class="keyword">module</span>;</span><br></pre></td></tr></table></figure><p>还需要对应修改<code>GCNv2_SLAM/src/GCNextractor.cc</code>的270行：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//原代码</span></span><br><span class="line"><span class="keyword">auto</span> output = <span class="keyword">module</span>-&gt;forward(inputs).<span class="built_in">toTuple</span>();</span><br><span class="line"><span class="comment">//更改为</span></span><br><span class="line"><span class="keyword">auto</span> output = <span class="keyword">module</span>.forward(inputs).<span class="built_in">toTuple</span>();</span><br></pre></td></tr></table></figure><h4 id="4-2-3-标准库chrono编译问题"><a href="#4-2-3-标准库chrono编译问题" class="headerlink" title="4.2.3. 标准库chrono编译问题"></a>4.2.3. 标准库chrono编译问题</h4><p>如果你的cmake修改不对，还可能会遇到chrono导致的编译报错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">/root/autodl-tmp/GCNv2_SLAM/GCN2/rgbd_gcn.cc: In function ‘int main(int, char**)’:</span><br><span class="line">/root/autodl-tmp/GCNv2_SLAM/GCN2/rgbd_gcn.cc:97:22: error: ‘std::chrono::monotonic_clock’ has not been declared</span><br><span class="line">         std::chrono::monotonic_clock::time_point t1 = std::chrono::monotonic_clock::now();</span><br><span class="line">                      ^~~~~~~~~~~~~~~</span><br><span class="line">/root/autodl-tmp/GCNv2_SLAM/GCN2/rgbd_gcn.cc:106:22: error: ‘std::chrono::monotonic_clock’ has not been declared</span><br><span class="line">         std::chrono::monotonic_clock::time_point t2 = std::chrono::monotonic_clock::now();</span><br><span class="line">                      ^~~~~~~~~~~~~~~</span><br><span class="line">/root/autodl-tmp/GCNv2_SLAM/GCN2/rgbd_gcn.cc:109:84: error: ‘t2’ was not declared in this scope</span><br><span class="line">         double ttrack = std::chrono::duration_cast&lt;std::chrono::duration&lt;double&gt; &gt;(t2 - t1).count();</span><br><span class="line">                                                                                    ^~</span><br><span class="line">/root/autodl-tmp/GCNv2_SLAM/GCN2/rgbd_gcn.cc:109:84: note: suggested alternative: ‘tm’</span><br><span class="line">         double ttrack = std::chrono::duration_cast&lt;std::chrono::duration&lt;double&gt; &gt;(t2 - t1).count();</span><br><span class="line">                                                                                    ^~</span><br><span class="line">                                                                                    tm</span><br><span class="line">/root/autodl-tmp/GCNv2_SLAM/GCN2/rgbd_gcn.cc:109:89: error: ‘t1’ was not declared in this scope</span><br><span class="line">         double ttrack = std::chrono::duration_cast&lt;std::chrono::duration&lt;double&gt; &gt;(t2 - t1).count();</span><br><span class="line">                                                                                         ^~</span><br><span class="line">/root/autodl-tmp/GCNv2_SLAM/GCN2/rgbd_gcn.cc:109:89: note: suggested alternative: ‘tm’</span><br><span class="line">         double ttrack = std::chrono::duration_cast&lt;std::chrono::duration&lt;double&gt; &gt;(t2 - t1).count();</span><br><span class="line">                                                                                         ^~</span><br><span class="line">                                                                                         tm</span><br><span class="line">^CCMakeFiles/rgbd_gcn.dir/build.make:62: recipe for target &#x27;CMakeFiles/rgbd_gcn.dir/GCN2/rgbd_gcn.cc.o&#x27; failed</span><br><span class="line">make[2]: *** [CMakeFiles/rgbd_gcn.dir/GCN2/rgbd_gcn.cc.o] Interrupt</span><br><span class="line">CMakeFiles/Makefile2:67: recipe for target &#x27;CMakeFiles/rgbd_gcn.dir/all&#x27; failed</span><br><span class="line">make[1]: *** [CMakeFiles/rgbd_gcn.dir/all] Interrupt</span><br><span class="line">Makefile:83: recipe for target &#x27;all&#x27; failed</span><br><span class="line">make: *** [all] Interrupt</span><br></pre></td></tr></table></figure><p>错误的主要含义就是<code>std::chrono::monotonic_clock</code>不存在，这是老版本的一个类，C++11新版本已经给它删掉了。查看<code>GCN2/rgbd_gcn.cc</code>代码可以发现，这里有宏定义来区分</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// GCNv2_SLAM/GCN2/rgbd_gcn.cc</span></span><br><span class="line"><span class="meta">#<span class="keyword">ifdef</span> COMPILEDWITHC11</span></span><br><span class="line">        std::chrono::steady_clock::time_point t1 = std::chrono::steady_clock::<span class="built_in">now</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">else</span></span></span><br><span class="line">        std::chrono::monotonic_clock::time_point t1 = std::chrono::monotonic_clock::<span class="built_in">now</span>();</span><br><span class="line"><span class="meta">#<span class="keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>前文提到的<code>GCNv2_SLAM/CMakeLists.txt</code>中需要保留<code>add_definitions(-DCOMPILEDWITHC11)</code>就是这个原因。有了这个宏定义此处代码就会编译<code>std::chrono::steady_clock</code>，不会有编译错误了。</p><h4 id="4-2-4-修改PT文件"><a href="#4-2-4-修改PT文件" class="headerlink" title="4.2.4. 修改PT文件"></a>4.2.4. 修改PT文件</h4><p>依旧需要修改3个pt文件，注意这时候修改的内容和CPU运行不一样！</p><p>修改<code>GCNv2_SLAM/GCN2</code>下gcn2_320x240.pt、gcn2_640x480.pt和gcn2_tiny_320x240.pt中的内容。需要先解压文件</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">unzip gcn2_320x240.pt</span><br></pre></td></tr></table></figure><p>解压出来之后会有<code>GCNv2_SLAM/GCN2/gcn/code/gcn.py</code>文件，这里的<code>grid_sampler</code>函数在pytorch 1.3.0之前是默认传入True的，1.3.0改成默认False了，所以需要手动传入True</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 原代码</span></span><br><span class="line">_32 = torch.squeeze(torch.grid_sampler(<span class="built_in">input</span>, grid, <span class="number">0</span>, <span class="number">0</span>))</span><br><span class="line"><span class="comment"># 修改为</span></span><br><span class="line">_32 = torch.squeeze(torch.grid_sampler(<span class="built_in">input</span>, grid, <span class="number">0</span>, <span class="number">0</span>, <span class="literal">True</span>))</span><br></pre></td></tr></table></figure><p>替换了之后，重新压缩pt文件，先删了原本的，重新压缩</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf gcn2_320x240.pt</span><br><span class="line">zip -r gcn2_320x240.pt gcn</span><br><span class="line"><span class="built_in">rm</span> -rf gcn <span class="comment">#删除刚刚的gcn文件夹</span></span><br></pre></td></tr></table></figure><p>这只是一个例子，其他几个gcn2压缩包都要用相同的方式修改！</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">unzip gcn2_640x480.pt</span><br><span class="line"><span class="built_in">rm</span> -rf gcn2_640x480.pt</span><br><span class="line"><span class="comment"># 修改下面这个文件</span></span><br><span class="line"><span class="comment">#   GCNv2_SLAM/GCN2/gcn2_480x640/code/gcn2_480x640.py</span></span><br><span class="line"><span class="comment"># 重新压缩</span></span><br><span class="line">zip -r gcn2_640x480.pt gcn2_480x640</span><br><span class="line"><span class="built_in">rm</span> -rf gcn2_480x640</span><br></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">unzip gcn2_tiny_320x240.pt</span><br><span class="line"><span class="built_in">rm</span> -rf gcn2_tiny_320x240.pt</span><br><span class="line"><span class="comment"># 修改文件</span></span><br><span class="line"><span class="comment">#   gcnv2slam/GCNv2_SLAM/GCN2/gcn2_tiny/code/gcn2_tiny.py</span></span><br><span class="line"><span class="comment"># 重新压缩</span></span><br><span class="line">zip -r gcn2_tiny_320x240.pt gcn2_tiny</span><br><span class="line"><span class="built_in">rm</span> -rf gcn2_tiny</span><br></pre></td></tr></table></figure><h3 id="4-3-编译项目"><a href="#4-3-编译项目" class="headerlink" title="4.3. 编译项目"></a>4.3. 编译项目</h3><p>修改了上面提到的几处问题，就能正常编译成功了</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/a67122422a0a7f536f5e1fe241ef06d3.png" alt="image.png"></p><p>如果需要从头重新编译项目，需要删除build目录缓存。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf Thirdparty/g2o/build/</span><br><span class="line"><span class="built_in">rm</span> -rf Thirdparty/DBoW2/build/</span><br><span class="line"><span class="built_in">rm</span> -rf Vocabulary/*.bin</span><br><span class="line"><span class="built_in">rm</span> -rf ./build</span><br></pre></td></tr></table></figure><h2 id="5-配置VNC环境"><a href="#5-配置VNC环境" class="headerlink" title="5. 配置VNC环境"></a>5. 配置VNC环境</h2><h3 id="5-1-安装VNC服务端"><a href="#5-1-安装VNC服务端" class="headerlink" title="5.1. 安装VNC服务端"></a>5.1. 安装VNC服务端</h3><p>默认情况下autodl是没有GUI环境的，也就没有办法运行项目（会有x11报错）</p><p>所以我们需要依照官方文档来配置一下GUI：<a target="_blank" rel="noopener" href="https://www.autodl.com/docs/gui/">www.autodl.com/docs/gui/</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装基本的依赖包</span></span><br><span class="line">apt update &amp;&amp; apt install -y libglu1-mesa-dev mesa-utils xterm xauth x11-xkb-utils xfonts-base xkb-data libxtst6 libxv1</span><br><span class="line"></span><br><span class="line"><span class="comment"># 安装libjpeg-turbo和turbovnc</span></span><br><span class="line"><span class="built_in">export</span> TURBOVNC_VERSION=2.2.5</span><br><span class="line"><span class="built_in">export</span> LIBJPEG_VERSION=2.0.90</span><br><span class="line">wget http://aivc.ks3-cn-beijing.ksyun.com/packages/libjpeg-turbo/libjpeg-turbo-official_<span class="variable">$&#123;LIBJPEG_VERSION&#125;</span>_amd64.deb</span><br><span class="line">wget http://aivc.ks3-cn-beijing.ksyun.com/packages/turbovnc/turbovnc_<span class="variable">$&#123;TURBOVNC_VERSION&#125;</span>_amd64.deb</span><br><span class="line">dpkg -i libjpeg-turbo-official_<span class="variable">$&#123;LIBJPEG_VERSION&#125;</span>_amd64.deb</span><br><span class="line">dpkg -i turbovnc_<span class="variable">$&#123;TURBOVNC_VERSION&#125;</span>_amd64.deb</span><br><span class="line"><span class="built_in">rm</span> -rf *.deb</span><br><span class="line"></span><br><span class="line"><span class="comment"># 启动VNC服务端，这一步可能涉及vnc密码配置（注意不是实例的账户密码）。另外如果出现报错xauth未找到，那么使用apt install xauth再安装一次</span></span><br><span class="line"><span class="built_in">rm</span> -rf /tmp/.X1*  <span class="comment"># 如果再次启动，删除上一次的临时文件，否则无法正常启动</span></span><br><span class="line">USER=root /opt/TurboVNC/bin/vncserver :1 -desktop X -auth /root/.Xauthority -geometry 1920x1080 -depth 24 -rfbwait 120000 -rfbauth /root/.vnc/passwd -fp /usr/share/fonts/X11/misc/,/usr/share/fonts -rfbport 6006</span><br><span class="line"></span><br><span class="line"><span class="comment"># 检查是否启动，如果有vncserver的进程，证明已经启动</span></span><br><span class="line">ps -ef | grep vnc | grep -v grep</span><br></pre></td></tr></table></figure><p>启动vnc服务端会让你输入密码，为了方便我直接用了autodl实例的密码。只读密码<code>view-only password</code>选择n不设置。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@autodl-container-e39d46b8d3-01da7b14:~/vnc]$ USER=root /opt/TurboVNC/bin/vncserver :1 -desktop X -auth /root/.Xauthority -geometry 1920x1080 -depth 24 -rfbwait 120000 -rfbauth /root/.vnc/passwd -fp /usr/share/fonts/X11/misc/,/usr/share/fonts -rfbport 6006</span><br><span class="line"></span><br><span class="line">You will require a password to access your desktops.</span><br><span class="line"></span><br><span class="line">Password: </span><br><span class="line">Warning: password truncated to the length of 8.</span><br><span class="line">Verify:   </span><br><span class="line">Would you like to enter a view-only password (y/n)? n</span><br><span class="line">xauth:  file /root/.Xauthority does not exist</span><br><span class="line"></span><br><span class="line">Desktop &#x27;TurboVNC: autodl-container-e39d46b8d3-01da7b14:1 (root)&#x27; started on display autodl-container-e39d46b8d3-01da7b14:1</span><br><span class="line"></span><br><span class="line">Creating default startup script /root/.vnc/xstartup.turbovnc</span><br><span class="line">Starting applications specified in /root/.vnc/xstartup.turbovnc</span><br><span class="line">Log file is /root/.vnc/autodl-container-e39d46b8d3-01da7b14:1.log</span><br></pre></td></tr></table></figure><p>启动vnc服务端后就能搜到进程了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/vnc# ps -ef | grep vnc | grep -v grep</span><br><span class="line">root      28861      1  0 11:22 pts/0    00:00:00 /opt/TurboVNC/bin/Xvnc :1 -desktop TurboVNC: autodl-container-64eb44b6f5-c569ba8d:1 (root) -httpd /opt/TurboVNC/bin//../java -auth /root/.Xauthority -geometr</span><br></pre></td></tr></table></figure><p>如果关闭了实例之后需要重启vnc，执行这两个命令就行了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">rm</span> -rf /tmp/.X1*  <span class="comment"># 如果再次启动，删除上一次的临时文件，否则无法正常启动</span></span><br><span class="line">USER=root /opt/TurboVNC/bin/vncserver :1 -desktop X -auth /root/.Xauthority -geometry 1920x1080 -depth 24 -rfbwait 120000 -rfbauth /root/.vnc/passwd -fp /usr/share/fonts/X11/misc/,/usr/share/fonts -rfbport 6006</span><br></pre></td></tr></table></figure><h3 id="5-2-本地端口绑定"><a href="#5-2-本地端口绑定" class="headerlink" title="5.2. 本地端口绑定"></a>5.2. 本地端口绑定</h3><p>随后还需要进行本地ssh端口绑定，先到autodl的控制台实例列表里面复制一下ssh链接命令，应该长这样</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -p 端口号 root@域名</span><br></pre></td></tr></table></figure><p>使用下面这个命令在本地的终端运行，就能实现把远程的端口绑定到本地的6006端口了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssh -CNgv -L 6006:127.0.0.1:6006 root@域名 -p 端口号</span><br></pre></td></tr></table></figure><p>如果命令正确，输入这个命令后会让你键入autodl实例的密码，在控制台里面复制然后ctrl+shift+v（command+v）粘贴就行了。</p><p>期间需要保持这个终端一直开启，不然转发会终止。</p><h3 id="5-3-链接VNC"><a href="#5-3-链接VNC" class="headerlink" title="5.3. 链接VNC"></a>5.3. 链接VNC</h3><p>这里我使用了祖传的<a target="_blank" rel="noopener" href="https://www.realvnc.com/en/connect/download/viewer/">VNC Viewer</a>来连云端，全平台都有客户端，下载安装就可以了。</p><p>安装了之后，直接在顶栏输入<code>127.0.0.1:6006</code>来链接云端。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/54f3efbf747088dde3378beaae3b2de3.png" alt="image.png"></p><p>如果提示connection closed大概率是vnc服务没有正常安装或者端口转发没有成功，请重试上述步骤。顺利的话，就会弹出来让你输入密码。</p><p><strong>这里的密码是启动vnc服务端时设置的密码</strong>，根据你设置的密码输入就行。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/12ae5231f3cd6a02a793333cf3dc4841.png"></p><p>链接成功，会是黑屏，正常情况</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/e5b8b4825b46610a7b1dc41a36934b62.png" alt="image.png"></p><h3 id="5-4-测试VNC是否安装成功"><a href="#5-4-测试VNC是否安装成功" class="headerlink" title="5.4. 测试VNC是否安装成功"></a>5.4. 测试VNC是否安装成功</h3><p>我们可以用Pangolin的示例程序来试试有没有配置成功</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> Pangolin-0.6/examples/HelloPangolin</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build</span><br><span class="line">cmake ..</span><br><span class="line">make</span><br></pre></td></tr></table></figure><p>编译完成之后需要先执行<code>export DISPLAY=:1</code>启用GUI再启动需要GUI的程序</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> DISPLAY=:1</span><br><span class="line">./HelloPangolin </span><br></pre></td></tr></table></figure><p>如果没有export直接启动，还是会报错</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/autodl-tmp/Pangolin-0.6/examples/HelloPangolin/build# ./HelloPangolin </span><br><span class="line">terminate called after throwing an instance of &#x27;std::runtime_error&#x27;</span><br><span class="line">  what():  Pangolin X11: Failed to open X display</span><br><span class="line">Aborted (core dumped)</span><br></pre></td></tr></table></figure><p>export了环境变量之后就能正常启动，且VNC里面也能看到画面了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/autodl-tmp/Pangolin-0.6/examples/HelloPangolin/build# export DISPLAY=:1</span><br><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/autodl-tmp/Pangolin-0.6/examples/HelloPangolin/build# ./HelloPangolin </span><br></pre></td></tr></table></figure><p>出现下面这个魔方就是安装VNC成功啦</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/50899e86b90c9553dee4da5655e76ed4.png" alt="image.png"></p><p>你也可以编译opencv的demo来测试vnc是否正常</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> opencv-3.4.5/samples/cpp/example_cmake</span><br><span class="line"><span class="built_in">mkdir</span> build &amp;&amp; <span class="built_in">cd</span> build </span><br><span class="line">cmake ..</span><br><span class="line">make</span><br><span class="line"><span class="comment"># 导入环境变量之后再启动</span></span><br><span class="line"><span class="built_in">export</span> DISPLAY=:1</span><br><span class="line">./opencv_example</span><br></pre></td></tr></table></figure><p>如果正常，vnc里面会出现一个hello opencv，因为没有摄像头所以是黑屏</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/b2fb06eb34c33fb8cf008136419e0cc9.png" alt="image.png"></p><h2 id="6-运行GCNv2-SLAM分析TUM数据集"><a href="#6-运行GCNv2-SLAM分析TUM数据集" class="headerlink" title="6. 运行GCNv2_SLAM分析TUM数据集"></a>6. 运行GCNv2_SLAM分析TUM数据集</h2><p>接下来就可以运行项目了，还是去下载TUM数据集，这里把之前博客的命令copy过来。</p><h3 id="6-1-下载数据集"><a href="#6-1-下载数据集" class="headerlink" title="6.1. 下载数据集"></a>6.1. 下载数据集</h3><p>下载地址：<a target="_blank" rel="noopener" href="https://cvg.cit.tum.de/data/datasets/rgbd-dataset/download">cvg.cit.tum.de&#x2F;data&#x2F;datasets&#x2F;rgbd-dataset&#x2F;download</a></p><p>下载<code>fr1/desk</code>数据集，这是一个桌子的RGBD数据</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/01/6ebeb1fe9366e07ea5dd7f0697b72d4f.png" alt="image.png"></p><p>在GCNv2_SLAM工程下新建<code>datasets/TUM</code>,将数据集下载到其中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 新建datasets/TUM数据集文件夹</span></span><br><span class="line"><span class="built_in">mkdir</span> -p datasets/TUM </span><br><span class="line"><span class="built_in">cd</span> datasets/TUM</span><br><span class="line"><span class="comment"># 下载数据集到datasets/TUM文件夹内</span></span><br><span class="line">wget -O rgbd_dataset_freiburg1_desk.tgz https://cvg.cit.tum.de/rgbd/dataset/freiburg1/rgbd_dataset_freiburg1_desk.tgz</span><br><span class="line"><span class="comment"># 解压数据集</span></span><br><span class="line">tar -xvf rgbd_dataset_freiburg1_desk.tgz</span><br></pre></td></tr></table></figure><p>然后还需要下载一个<code>associate.py</code>脚本来处理一下数据集才能正常运行</p><p>下载地址：<a target="_blank" rel="noopener" href="https://svncvpr.in.tum.de/cvpr-ros-pkg/trunk/rgbd_benchmark/rgbd_benchmark_tools/src/rgbd_benchmark_tools/associate.py">svncvpr.in.tum.de</a>，同时在<a target="_blank" rel="noopener" href="https://github.com/musnows/GCNv2_SLAM/blob/86c1efc0cc6c40669df20c0a62017815e18771b7/docker/associate.py">我的Github仓库</a>也做了留档。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">wget -O associate.py https://svncvpr.in.tum.de/cvpr-ros-pkg/trunk/rgbd_benchmark/rgbd_benchmark_tools/src/rgbd_benchmark_tools/associate.py</span><br></pre></td></tr></table></figure><p>这个脚本只能用python2运行，需要下载numpy库。注意autodl的环境中python绑定到了python3，环境中的python2被拦掉了，所以需要安装独立的python2命令来运行python2。</p><p>在Pytorch1.5.1版本的autodl镜像中，可以直接使用下面的命令来安装python2和pip2：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">apt-get install -y python-dev python-pip</span><br></pre></td></tr></table></figure><p>随后安装numpy库就ok了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-e39d46b8d3-01da7b14:~/autodl-tmp/GCNv2_SLAM/datasets/TUM# pip2 install numpy</span><br><span class="line">DEPRECATION: Python 2.7 reached the end of its life on January 1st, 2020. Please upgrade your Python as Python 2.7 is no longer maintained. pip 21.0 will drop support for Python 2.7 in January 2021. More details about Python 2 support in pip can be found at https://pip.pypa.io/en/latest/development/release-process/#python-2-support pip 21.0 will remove support for this functionality.</span><br><span class="line">Looking in indexes: http://mirrors.aliyun.com/pypi/simple</span><br><span class="line">Collecting numpy</span><br><span class="line">  Downloading http://mirrors.aliyun.com/pypi/packages/3a/5f/47e578b3ae79e2624e205445ab77a1848acdaa2929a00eeef6b16eaaeb20/numpy-1.16.6-cp27-cp27mu-manylinux1_x86_64.whl (17.0 MB)</span><br><span class="line">     |████████████████████████████████| 17.0 MB 21.1 MB/s </span><br><span class="line">Installing collected packages: numpy</span><br><span class="line">Successfully installed numpy-1.16.6</span><br></pre></td></tr></table></figure><p>执行脚本来处理两个文件，在数据文件夹里执行命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python2 associate.py rgbd_dataset_freiburg1_desk/rgb.txt rgbd_dataset_freiburg1_desk/depth.txt &gt; rgbd_dataset_freiburg1_desk/associate.txt</span><br></pre></td></tr></table></figure><p>执行python命令后可以看看合并成功了没有，如下应该就是没问题了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1305031472.895713 rgb/1305031472.895713.png 1305031472.892944 depth/1305031472.892944.png</span><br><span class="line">1305031472.927685 rgb/1305031472.927685.png 1305031472.924814 depth/1305031472.924814.png</span><br><span class="line">1305031472.963756 rgb/1305031472.963756.png 1305031472.961213 depth/1305031472.961213.png</span><br></pre></td></tr></table></figure><p>在同一个网站下载的其他TUM数据集也需要用相同的方式进行处理</p><h3 id="6-2-运行项目"><a href="#6-2-运行项目" class="headerlink" title="6.2. 运行项目"></a>6.2. 运行项目</h3><p>随后进入项目的GCN2目录执行命令，我把命令中的路径都改成了相对路径</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 注意需要导入vnc环境变量</span></span><br><span class="line"><span class="built_in">export</span> DISPLAY=:1</span><br><span class="line"><span class="comment"># 运行项目</span></span><br><span class="line"><span class="built_in">cd</span> GCN2</span><br><span class="line">GCN_PATH=gcn2_320x240.pt ./rgbd_gcn ../Vocabulary/GCNvoc.bin TUM3_small.yaml ../datasets/TUM/rgbd_dataset_freiburg1_desk ../datasets/TUM/rgbd_dataset_freiburg1_desk/associate.txt</span><br></pre></td></tr></table></figure><p>项目能正常运行，VNC中也有图像输出</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/90d472a3a51c0e26823a5d4e0249e583.png" alt="image.png"></p><p>运行结束后的输出如下</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">[root@autodl-container-e39d46b8d3-01da7b14:~/autodl-tmp/GCNv2_SLAM/GCN2]$ GCN_PATH=gcn2_320x240.pt ./rgbd_gcn ../Vocabulary/GCNvoc.bin TUM3_small.yaml ../datasets/TUM/rgbd_dataset_freiburg1_desk ../datasets/TUM/rgbd_dataset_freiburg1_desk/associate.txt</span><br><span class="line"></span><br><span class="line">ORB-SLAM2 Copyright (C) 2014-2016 Raul Mur-Artal, University of Zaragoza.</span><br><span class="line">This program comes with ABSOLUTELY NO WARRANTY;</span><br><span class="line">This is free software, and you are welcome to redistribute it</span><br><span class="line">under certain conditions. See LICENSE.txt.</span><br><span class="line"></span><br><span class="line">Input sensor was set to: RGB-D</span><br><span class="line"></span><br><span class="line">Loading ORB Vocabulary. This could take a while...</span><br><span class="line">Vocabulary loaded!</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Camera Parameters: </span><br><span class="line">- fx: 267.7</span><br><span class="line">- fy: 269.6</span><br><span class="line">- cx: 160.05</span><br><span class="line">- cy: 123.8</span><br><span class="line">- k1: 0</span><br><span class="line">- k2: 0</span><br><span class="line">- p1: 0</span><br><span class="line">- p2: 0</span><br><span class="line">- fps: 30</span><br><span class="line">- color order: RGB (ignored if grayscale)</span><br><span class="line"></span><br><span class="line">ORB Extractor Parameters: </span><br><span class="line">- Number of Features: 1000</span><br><span class="line">- Scale Levels: 8</span><br><span class="line">- Scale Factor: 1.2</span><br><span class="line">- Initial Fast Threshold: 20</span><br><span class="line">- Minimum Fast Threshold: 7</span><br><span class="line"></span><br><span class="line">Depth Threshold (Close/Far Points): 5.97684</span><br><span class="line"></span><br><span class="line">-------</span><br><span class="line">Start processing sequence ...</span><br><span class="line">Images in the sequence: 573</span><br><span class="line"></span><br><span class="line">Framebuffer with requested attributes not available. Using available framebuffer. You may see visual artifacts.New map created with 251 points</span><br><span class="line">Finished!</span><br><span class="line">-------</span><br><span class="line"></span><br><span class="line">median tracking time: 0.0187857</span><br><span class="line">mean tracking time: 0.0193772</span><br><span class="line"></span><br><span class="line">Saving camera trajectory to CameraTrajectory.txt ...</span><br><span class="line"></span><br><span class="line">trajectory saved!</span><br><span class="line"></span><br><span class="line">Saving keyframe trajectory to KeyFrameTrajectory.txt ...</span><br><span class="line"></span><br><span class="line">trajectory saved!</span><br></pre></td></tr></table></figure><p>用时0.0187857，约合53hz，和论文里面GTX1070laptop的80hz还是差的有点远。</p><p>后面又跑了几次，结果更慢了。不过整体还是比CPU运行快了n多倍了！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">median tracking time: 0.0225817</span><br><span class="line">mean tracking time: 0.0236844</span><br></pre></td></tr></table></figure><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/586e7b5cb58e0d06104c7cba18674c8d.png"></p><h2 id="7-尝试4090运行失败"><a href="#7-尝试4090运行失败" class="headerlink" title="7. 尝试4090运行失败"></a>7. 尝试4090运行失败</h2><h3 id="7-1-环境配置（PyTorch-1-11-0）"><a href="#7-1-环境配置（PyTorch-1-11-0）" class="headerlink" title="7.1. 环境配置（PyTorch 1.11.0）"></a>7.1. 环境配置（PyTorch 1.11.0）</h3><p>我尝试使用过4090显卡，环境如下。4090没办法选更低版本的PyTorch了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PyTorch  1.11.0</span><br><span class="line">Python  3.8(ubuntu20.04)</span><br><span class="line">Cuda  11.3</span><br></pre></td></tr></table></figure><p><strong>依赖项都用相同的命令安装</strong>，以下是安装依赖项时的部分截图。</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/683388a19f6bf7cd4023774a4d6ed745.png"></p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/4092f72fabfdc9ef3e38e732b36a1dd5.png"></p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/3ba57ba8d3591426e8988e55117a1aef.png" alt="image.png"></p><p>对应的Pytorch 1.11.0版本的libtorch下载链接如下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://download.pytorch.org/libtorch/cu113/libtorch-cxx11-abi-shared-with-deps-1.11.0%2Bcu113.zip</span><br></pre></td></tr></table></figure><p>整个包比较大，一共有1.6GB，需要慢慢等待下载了。建议还是本地提前下好再传上去，毕竟autodl每一分钟都是钱呐！</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/b84a9e7819ee2b4179df0a74a62daaf5.png" alt="image.png"></p><p>最终项目可以正常编译完成（也需要执行上文提到的代码修改）</p><p><img src="/img/loading.gif" data-lazy-src="https://img.musnow.top/i/2025/02/e65a1b852168d63fa22cc2030323ecc7.png" alt="image.png"></p><h3 id="7-2-数据集处理"><a href="#7-2-数据集处理" class="headerlink" title="7.2. 数据集处理"></a>7.2. 数据集处理</h3><p>在Pytorch1.11.0镜像中需要用下面的方式安装python2来处理数据集，主要是python-pip包会提示不可用，没办法直接安装。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 安装python2</span></span><br><span class="line">apt-get install -y python-dev-is-python2</span><br><span class="line"><span class="comment"># 安装pip2</span></span><br><span class="line">wget https://bootstrap.pypa.io/pip/2.7/get-pip.py</span><br><span class="line">python2 get-pip.py</span><br></pre></td></tr></table></figure><p>获取到的python2如下，随后正常安装numpy来运行脚本就行了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">root@autodl-container-64eb44b6f5-c569ba8d:~# python2 -V</span><br><span class="line">Python 2.7.18</span><br><span class="line">root@autodl-container-64eb44b6f5-c569ba8d:~# pip2 -V</span><br><span class="line">pip 20.3.4 from /usr/local/lib/python2.7/dist-packages/pip (python 2.7)</span><br></pre></td></tr></table></figure><h3 id="7-3-运行GCN2发生coredump"><a href="#7-3-运行GCN2发生coredump" class="headerlink" title="7.3. 运行GCN2发生coredump"></a>7.3. 运行GCN2发生coredump</h3><p>还是用相同的命令启动程序</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">export</span> DISPLAY=:1</span><br><span class="line"><span class="built_in">cd</span> GCN2</span><br><span class="line">GCN_PATH=gcn2_320x240.pt ./rgbd_gcn ../Vocabulary/GCNvoc.bin TUM3_small.yaml ../datasets/TUM/rgbd_dataset_freiburg1_desk ../datasets/TUM/rgbd_dataset_freiburg1_desk/associate.txt</span><br></pre></td></tr></table></figure><p>完蛋，coredump了！</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">Camera Parameters: </span><br><span class="line">- fx: 267.7</span><br><span class="line">- fy: 269.6</span><br><span class="line">- cx: 160.05</span><br><span class="line">- cy: 123.8</span><br><span class="line">- k1: 0</span><br><span class="line">- k2: 0</span><br><span class="line">- p1: 0</span><br><span class="line">- p2: 0</span><br><span class="line">- fps: 30</span><br><span class="line">- color order: RGB (ignored if grayscale)</span><br><span class="line">terminate called after throwing an instance of &#x27;c10::Error&#x27;</span><br><span class="line">  what():  Legacy model format is not supported on mobile.</span><br><span class="line">Exception raised from deserialize at ../torch/csrc/jit/serialization/import.cpp:267 (most recent call first):</span><br><span class="line">frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;) + 0x6b (0x7fefb6de20eb in /root/autodl-tmp/libtorch/lib/libc10.so)</span><br><span class="line">frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, char const*) + 0xd1 (0x7fefb6dddc41 in /root/autodl-tmp/libtorch/lib/libc10.so)</span><br><span class="line">frame #2: &lt;unknown function&gt; + 0x35dd53d (0x7feff3ef353d in /root/autodl-tmp/libtorch/lib/libtorch_cpu.so)</span><br><span class="line">frame #3: torch::jit::load(std::shared_ptr&lt;caffe2::serialize::ReadAdapterInterface&gt;, c10::optional&lt;c10::Device&gt;, std::unordered_map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt; &gt;&amp;) + 0x1cd (0x7feff3ef48ad in /root/autodl-tmp/libtorch/lib/libtorch_cpu.so)</span><br><span class="line">frame #4: torch::jit::load(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, c10::optional&lt;c10::Device&gt;, std::unordered_map&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;, std::hash&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::equal_to&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt;, std::allocator&lt;std::pair&lt;std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; &gt; &gt; &gt;&amp;) + 0xc1 (0x7feff3ef64c1 in /root/autodl-tmp/libtorch/lib/libtorch_cpu.so)</span><br><span class="line">frame #5: torch::jit::load(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, c10::optional&lt;c10::Device&gt;) + 0x6f (0x7feff3ef65cf in /root/autodl-tmp/libtorch/lib/libtorch_cpu.so)</span><br><span class="line">frame #6: ORB_SLAM2::GCNextractor::GCNextractor(int, float, int, int, int) + 0x670 (0x7ff071e213c0 in /root/autodl-tmp/GCNv2_SLAM/lib/libORB_SLAM2.so)</span><br><span class="line">frame #7: ORB_SLAM2::Tracking::Tracking(ORB_SLAM2::System*, DBoW2::TemplatedVocabulary&lt;cv::Mat, DBoW2::FORB&gt;*, ORB_SLAM2::FrameDrawer*, ORB_SLAM2::MapDrawer*, ORB_SLAM2::Map*, ORB_SLAM2::KeyFrameDatabase*, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, int) + 0x1e7e (0x7ff071dfcf0e in /root/autodl-tmp/GCNv2_SLAM/lib/libORB_SLAM2.so)</span><br><span class="line">frame #8: ORB_SLAM2::System::System(std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, std::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt; const&amp;, ORB_SLAM2::System::eSensor, bool) + 0x5ae (0x7ff071de459e in /root/autodl-tmp/GCNv2_SLAM/lib/libORB_SLAM2.so)</span><br><span class="line">frame #9: main + 0x22f (0x5609d811ae2f in ./rgbd_gcn)</span><br><span class="line">frame #10: __libc_start_main + 0xf3 (0x7fefb704a083 in /lib/x86_64-linux-gnu/libc.so.6)</span><br><span class="line">frame #11: _start + 0x2e (0x5609d811c7ce in ./rgbd_gcn)</span><br><span class="line"></span><br><span class="line">Aborted (core dumped)</span><br></pre></td></tr></table></figure><p>GPT说此问题是因为save模型和load模型的PyTorch版本不一致，导致无法加载。如果不出意外的话GCNv2应该是用README里面写的PyTorch 1.0.1版本来保存模型的，可能是1.0.1版本已经和1.11.0版本完全不兼容了。</p><p>这个问题我没找到解决方案，于是放弃治疗。本来GCNv2就是一个很老的项目了，在40系显卡上不好运行也正常。网上其实能搜到一篇在<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_45482740/article/details/134299049">4060拯救者上运行GCNv2</a>的博客，但是那篇博客里面并没有提到这个coredump的问题，问GPT也没给出一个可行的方案，还是不浪费时间了。</p><h3 id="7-4-尝试使用-PyTorch-1-10-0-镜像"><a href="#7-4-尝试使用-PyTorch-1-10-0-镜像" class="headerlink" title="7.4. 尝试使用 PyTorch 1.10.0 镜像"></a>7.4. 尝试使用 PyTorch 1.10.0 镜像</h3><p>上面这个coredump搜到了几篇<a target="_blank" rel="noopener" href="https://github.com/LaurentMazare/tch-rs/issues/469">github issue</a>，有的提到了可能是PyTorch 1.11.0版本和之前版本的镜像加载方式不同，导致无法load镜像。所以尝试使用PyTorch 1.10.0版本来重新测试一下。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">PyTorch  1.10.0</span><br><span class="line">Python  3.8(ubuntu20.04)</span><br><span class="line">Cuda  11.3</span><br></pre></td></tr></table></figure><p>对应版本libtorch的下载链接，其他依赖项用上文提到的命令安装就可以了。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">https://download.pytorch.org/libtorch/cu113/libtorch-cxx11-abi-shared-with-deps-1.10.0%2Bcu113.zip</span><br></pre></td></tr></table></figure><p>然而并不行，依旧会有错误，这一次没有加载模型的error了，变成了段错误。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Start processing sequence ...</span><br><span class="line">Images in the sequence: 573</span><br><span class="line"></span><br><span class="line">Pass &#x27;Combine redundant instructions&#x27; is not initialized.</span><br><span class="line">Verify if there is a pass dependency cycle.</span><br><span class="line">Required Passes:</span><br><span class="line">Segmentation fault (core dumped)</span><br></pre></td></tr></table></figure><p>在类似项目<code>YOLO_ORB_SLAM3</code>的仓库中能找到相关的issue：<a target="_blank" rel="noopener" href="https://github.com/YWL0720/YOLO_ORB_SLAM3/issues/12">github.com&#x2F;YWL0720&#x2F;YOLO_ORB_SLAM3&#x2F;issues&#x2F;12</a>，依旧是libtorch版本不对导致的问题，issue中提到的解决办法是将libtorch降低到1.7.1版本。</p><p>看来是没辙啦，因为40系显卡至少需要CUDA 11.3版本，在AutoDL上最低只能选择到PyTorch 1.10.0的镜像了，没法装1.7.0的镜像。</p><p>不再尝试了。</p><h2 id="8-The-end"><a href="#8-The-end" class="headerlink" title="8. The end"></a>8. The end</h2><p>本文成功在2080ti的环境上运行了GCNv2_SLAM项目，虽然运行速度依旧抵不上论文中用1070laptop跑出来的80HZ，但总比本地CPU运行的龟速快多了。</p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="https://blog.musnow.top">慕雪年华</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://blog.musnow.top/posts/1071165018/">https://blog.musnow.top/posts/1071165018/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://blog.musnow.top" target="_blank">慕雪的寒舍</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Linux/">Linux</a><a class="post-meta__tags" href="/tags/Cpp/">Cpp</a><a class="post-meta__tags" href="/tags/SLAM/">SLAM</a></div><div class="post_share"><div class="social-share" data-image="https://img.musnow.top/i/2025/02/c16bf7fe837c06718a76843ba7b923eb.png" data-sites="wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/sharejs/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="https://ifdian.net/a/128ahri" target="_blank"><img class="post-qr-code-img" src="/img/ico/aifadian.png" alt="爱发电"></a><div class="post-qr-code-desc">爱发电</div></li></ul></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/posts/7873538113/" title="【SLAM】在本地虚拟机和AutoDL云端环境以TUM-RGBD数据集运行ORB_SLAM3"><img class="cover" src="https://img.musnow.top/i/2025/02/fb081dc6226497056b3613b2220e9aa9.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">【SLAM】在本地虚拟机和AutoDL云端环境以TUM-RGBD数据集运行ORB_SLAM3</div></div></a></div><div class="next-post pull-right"><a href="/posts/1589125738/" title="【SLAM】于ubuntu18.04上纯CPU运行GCNv2_SLAM的记录（ARM64/AMD64）"><img class="cover" src="https://img.musnow.top/i/2025/01/1cf6ea0426239abcba02e8a38ce24bea.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">【SLAM】于ubuntu18.04上纯CPU运行GCNv2_SLAM的记录（ARM64/AMD64）</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/posts/1589125738/" title="【SLAM】于ubuntu18.04上纯CPU运行GCNv2_SLAM的记录（ARM64&#x2F;AMD64）"><img class="cover" src="https://img.musnow.top/i/2025/01/1cf6ea0426239abcba02e8a38ce24bea.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-01-31</div><div class="title">【SLAM】于ubuntu18.04上纯CPU运行GCNv2_SLAM的记录（ARM64&#x2F;AMD64）</div></div></a></div><div><a href="/posts/5090585017/" title="【SLAM】在 ubuntu 18.04 arm 中以ROS环境编译与运行ORB_SLAM3"><img class="cover" src="https://img.musnow.top/i/2025/02/4532d161bce1a806b99e91a7f55c5097.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-09</div><div class="title">【SLAM】在 ubuntu 18.04 arm 中以ROS环境编译与运行ORB_SLAM3</div></div></a></div><div><a href="/posts/7873538113/" title="【SLAM】在本地虚拟机和AutoDL云端环境以TUM-RGBD数据集运行ORB_SLAM3"><img class="cover" src="https://img.musnow.top/i/2025/02/fb081dc6226497056b3613b2220e9aa9.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2025-02-04</div><div class="title">【SLAM】在本地虚拟机和AutoDL云端环境以TUM-RGBD数据集运行ORB_SLAM3</div></div></a></div></div></div><hr class="custom-hr"><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div id="artalk-wrap"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/favicon.jpg" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"></div><div class="author-info__name">慕雪年华</div><div class="author-info__description">爱折腾的代码初学者</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">429</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">73</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">22</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/musnows"><i class="fab fa-github"></i><span>Follow Me</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="mailto:muxue@musnow.top" target="_blank" title="email"><i class="fas fa-envelope"></i></a><a class="social-icon" href="https://gitee.com/musnows" target="_blank" title="Gitee"><i class="fa-sharp fa-solid fa-g"></i></a><a class="social-icon" href="https://blog.csdn.net/muxuen" target="_blank" title="CSDN"><i class="fa-brands fa-blogger-b"></i></a><a class="social-icon" href="https://musnow.top/?utm_source=blog" target="_blank" title="个人主页"><i class="fas fa-globe-asia"></i></a><a class="social-icon" href="https://web.musnow.top/?utm_source=blog" target="_blank" title="导航站点"><i class="fas fa-server"></i></a><a class="social-icon" href="/atom.xml" target="_blank" title="RSS"><i class="fas fa-rss-square"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">欢迎来到寒舍</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-%E5%BC%95%E5%AD%90"><span class="toc-text">1. 引子</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#2-AutoDL%E7%8E%AF%E5%A2%83%E9%80%89%E6%8B%A9"><span class="toc-text">2. AutoDL环境选择</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-%E4%BE%9D%E8%B5%96%E5%AE%89%E8%A3%85"><span class="toc-text">3. 依赖安装</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#3-1-%E9%9C%80%E8%A6%81%E7%9A%84apt%E5%8C%85%E5%AE%89%E8%A3%85"><span class="toc-text">3.1. 需要的apt包安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-2-Pangolin-6-0"><span class="toc-text">3.2. Pangolin-6.0</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-1-%E4%BE%9D%E8%B5%96%E9%A1%B9%E5%AE%89%E8%A3%85"><span class="toc-text">3.2.1. 依赖项安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-2-2-%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85"><span class="toc-text">3.2.2. 编译安装</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-3-OpenCV-3-4-5"><span class="toc-text">3.3. OpenCV 3.4.5</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-4-Eigen-3-7"><span class="toc-text">3.4. Eigen 3.7</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#3-5-Libtorch-1-5-0"><span class="toc-text">3.5. Libtorch 1.5.0</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-1-%E5%85%B3%E4%BA%8E%E6%89%8B%E5%B7%A5%E7%BC%96%E8%AF%91%E7%9A%84%E8%AF%B4%E6%98%8E"><span class="toc-text">3.5.1. 关于手工编译的说明</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-2-%E4%B8%8D%E8%83%BD%E4%BD%BF%E7%94%A8%E6%9C%AC%E5%9C%B0%E5%B7%B2%E6%9C%89%E7%9A%84%E7%89%88%E6%9C%AC"><span class="toc-text">3.5.2. 不能使用本地已有的版本</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#3-5-3-%E4%B8%8B%E8%BD%BD%E9%A2%84%E7%BC%96%E8%AF%91%E7%89%88%E6%9C%AC"><span class="toc-text">3.5.3. 下载预编译版本</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-%E7%BC%96%E8%AF%91GCNv2-SLAM"><span class="toc-text">4. 编译GCNv2_SLAM</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#4-1-%E4%BF%AE%E6%94%B9build-sh"><span class="toc-text">4.1. 修改build.sh</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-2-%E4%BF%AE%E6%94%B9%E4%BB%A3%E7%A0%81%E5%85%BC%E5%AE%B9%E9%AB%98%E7%89%88%E6%9C%AClibtorch"><span class="toc-text">4.2. 修改代码兼容高版本libtorch</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-1-C-14%E7%BC%96%E8%AF%91%E9%85%8D%E7%BD%AE"><span class="toc-text">4.2.1. C++14编译配置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-2-%E7%BC%BA%E5%B0%91%E5%AF%B9%E5%BA%94%E7%9A%84operator-x3D"><span class="toc-text">4.2.2. 缺少对应的operator&#x3D;</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-3-%E6%A0%87%E5%87%86%E5%BA%93chrono%E7%BC%96%E8%AF%91%E9%97%AE%E9%A2%98"><span class="toc-text">4.2.3. 标准库chrono编译问题</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#4-2-4-%E4%BF%AE%E6%94%B9PT%E6%96%87%E4%BB%B6"><span class="toc-text">4.2.4. 修改PT文件</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#4-3-%E7%BC%96%E8%AF%91%E9%A1%B9%E7%9B%AE"><span class="toc-text">4.3. 编译项目</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-%E9%85%8D%E7%BD%AEVNC%E7%8E%AF%E5%A2%83"><span class="toc-text">5. 配置VNC环境</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#5-1-%E5%AE%89%E8%A3%85VNC%E6%9C%8D%E5%8A%A1%E7%AB%AF"><span class="toc-text">5.1. 安装VNC服务端</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-2-%E6%9C%AC%E5%9C%B0%E7%AB%AF%E5%8F%A3%E7%BB%91%E5%AE%9A"><span class="toc-text">5.2. 本地端口绑定</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-3-%E9%93%BE%E6%8E%A5VNC"><span class="toc-text">5.3. 链接VNC</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#5-4-%E6%B5%8B%E8%AF%95VNC%E6%98%AF%E5%90%A6%E5%AE%89%E8%A3%85%E6%88%90%E5%8A%9F"><span class="toc-text">5.4. 测试VNC是否安装成功</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#6-%E8%BF%90%E8%A1%8CGCNv2-SLAM%E5%88%86%E6%9E%90TUM%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">6. 运行GCNv2_SLAM分析TUM数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#6-1-%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-text">6.1. 下载数据集</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#6-2-%E8%BF%90%E8%A1%8C%E9%A1%B9%E7%9B%AE"><span class="toc-text">6.2. 运行项目</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#7-%E5%B0%9D%E8%AF%954090%E8%BF%90%E8%A1%8C%E5%A4%B1%E8%B4%A5"><span class="toc-text">7. 尝试4090运行失败</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#7-1-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%EF%BC%88PyTorch-1-11-0%EF%BC%89"><span class="toc-text">7.1. 环境配置（PyTorch 1.11.0）</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-2-%E6%95%B0%E6%8D%AE%E9%9B%86%E5%A4%84%E7%90%86"><span class="toc-text">7.2. 数据集处理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-3-%E8%BF%90%E8%A1%8CGCN2%E5%8F%91%E7%94%9Fcoredump"><span class="toc-text">7.3. 运行GCN2发生coredump</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#7-4-%E5%B0%9D%E8%AF%95%E4%BD%BF%E7%94%A8-PyTorch-1-10-0-%E9%95%9C%E5%83%8F"><span class="toc-text">7.4. 尝试使用 PyTorch 1.10.0 镜像</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#8-The-end"><span class="toc-text">8. The end</span></a></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/8855455861/" title="【Hexo】hexo-butterfly主题添加影评书评页面">【Hexo】hexo-butterfly主题添加影评书评页面</a><time datetime="2025-02-12T05:49:29.000Z" title="发表于 2025-02-12 13:49:29">2025-02-12</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/5090585017/" title="【SLAM】在 ubuntu 18.04 arm 中以ROS环境编译与运行ORB_SLAM3">【SLAM】在 ubuntu 18.04 arm 中以ROS环境编译与运行ORB_SLAM3</a><time datetime="2025-02-09T08:18:59.000Z" title="发表于 2025-02-09 16:18:59">2025-02-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/3771271576/" title="【Linux】在 ubuntu 18.04 arm 容器中安装ROS环境">【Linux】在 ubuntu 18.04 arm 容器中安装ROS环境</a><time datetime="2025-02-09T05:06:07.000Z" title="发表于 2025-02-09 13:06:07">2025-02-09</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/posts/4031478666/" title="【Linux】解决使用apt时“unable to initialize frontend: Dialog”的警告">【Linux】解决使用apt时“unable to initialize frontend: Dialog”的警告</a><time datetime="2025-02-08T09:39:23.000Z" title="发表于 2025-02-08 17:39:23">2025-02-08</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(/img/main/mothra.webp)"><div id="footer-wrap"><div class="copyright">&copy;2021 - 2025 By 慕雪年华</div><div class="footer_custom_text"><img src="/img/ico/gonganbeian.png" height="15">&nbsp;<a href="https://beian.mps.gov.cn/#/query/webSearch?code=44190002007715" rel="noreferrer" target="_blank">粤公网安备44190002007715</a><br><a href="https://icp.gov.moe/?keyword=20230054" target="_blank"><img src="/img/badge/-%E8%90%8CICP%E5%A4%8720230054-ff69b4.svg" height="20px"></a>&nbsp<a href="/sitemap.xml" target="_blank"><img src="/img/badge/-SITEMAP-00CDCD.svg" height="20px"></a>&nbsp<a href="https://beian.miit.gov.cn/" target="_blank"><img src="/img/badge/%E7%B2%A4ICP%E5%A4%872023007189-red.svg" height="20px"></a><br><a href="https://www.foreverblog.cn/go.html" target="_blank"><img src="/img/ico/wormhole_1_tp.gif" height="25px"></a>&nbsp<a href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral" target="_blank"><img src="/img/ico/upyun_cdn_w.png" height="25px"></a>&nbsp<a href="https://www.travellings.cn/go.html" target="_blank"><img src="/img/ico/travelling_icon.gif" height="25px"></a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-butterfly/4.9.0/js/utils.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-butterfly/4.9.0/js/main.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.19/fancybox/fancybox.umd.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/vanilla-lazyload/17.8.3/lazyload.iife.min.js"></script><script>function panguFn () {
  if (typeof pangu === 'object') pangu.autoSpacingPage()
  else {
    getScript('https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js')
      .then(() => {
        pangu.autoSpacingPage()
      })
  }
}

function panguInit () {
  if (true){
    GLOBAL_CONFIG_SITE.isPost && panguFn()
  } else {
    panguFn()
  }
}

document.addEventListener('DOMContentLoaded', panguInit)</script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script><script>(() => {
  const $mermaid = document.querySelectorAll('#article-container .mermaid-wrap')
  if ($mermaid.length === 0) return
  const runMermaid = () => {
    window.loadMermaid = true
    const theme = document.documentElement.getAttribute('data-theme') === 'dark' ? 'dark' : 'default'

    Array.from($mermaid).forEach((item, index) => {
      const mermaidSrc = item.firstElementChild
      const mermaidThemeConfig = '%%{init:{ \'theme\':\'' + theme + '\'}}%%\n'
      const mermaidID = 'mermaid-' + index
      const mermaidDefinition = mermaidThemeConfig + mermaidSrc.textContent

      const renderFn = mermaid.render(mermaidID, mermaidDefinition)

      const renderV10 = () => {
        renderFn.then(({svg}) => {
          mermaidSrc.insertAdjacentHTML('afterend', svg)
        })
      }

      const renderV9 = svg => {
        mermaidSrc.insertAdjacentHTML('afterend', svg)
      }

      typeof renderFn === 'string' ? renderV9(renderFn) : renderV10()
    })
  }

  const loadMermaid = () => {
    window.loadMermaid ? runMermaid() : getScript('https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.2.2/mermaid.min.js').then(runMermaid)
  }

  btf.addModeChange('mermaid', runMermaid)

  window.pjax ? loadMermaid() : document.addEventListener('DOMContentLoaded', loadMermaid)
})()</script><script>function loadArtalk () {
  function initArtalk () {
    window.artalkItem = new Artalk(Object.assign({
      el: '#artalk-wrap',
      server: 'https://artk.musnow.top',
      site: 'mublog',
      pageKey: location.pathname,
      darkMode: document.documentElement.getAttribute('data-theme') === 'dark',
      countEl: '.artalk-count'
    },null))

    if (GLOBAL_CONFIG.lightbox === 'null') return
    window.artalkItem.use(ctx => {
      ctx.on('list-loaded', () => {
        ctx.getCommentList().forEach(comment => {
          const $content = comment.getRender().$content
          btf.loadLightbox($content.querySelectorAll('img:not([atk-emoticon])'))
        })
      })
    })
  }

  if (typeof window.artalkItem === 'object') initArtalk()
  else {
    getCSS('https://cdnjs.cloudflare.com/ajax/libs/artalk/2.5.5/Artalk.min.css').then(()=>{
      getScript('https://cdnjs.cloudflare.com/ajax/libs/artalk/2.5.5/Artalk.min.js').then(initArtalk)
    })
  }
}

function artalkChangeMode (theme) {
  const artalkWrap = document.getElementById('artalk-wrap')
  if (!(artalkWrap && artalkWrap.children.length)) return
  const isDark = theme === 'dark'
  window.artalkItem.setDarkMode(isDark)
}

btf.addModeChange('artalk', artalkChangeMode)

if ('Artalk' === 'Artalk' || !false) {
  if (false) btf.loadComment(document.getElementById('artalk-wrap'), loadArtalk)
  else loadArtalk()
} else {
  function loadOtherComment () {
    loadArtalk()
  }
}</script></div><script src="/js/domain_check.js"></script><script id="click-heart" src="https://cdnjs.cloudflare.com/ajax/libs/butterfly-extsrc/1.1.3/click-heart.min.js" async mobile="false"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><span id="loading-status"></span><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="is-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span> 数据库加载中</span></div><div class="search-wrap"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div><hr><div class="no-result" id="local-search-results"></div><div id="local-search-stats-wrap"></div></div></div><div id="search-mask"></div><script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-theme-butterfly/4.9.0/js/search/local-search.min.js"></script></div></div></body></html>